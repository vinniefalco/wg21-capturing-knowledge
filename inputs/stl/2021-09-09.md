WEBVTT

>> Miya: And you should be good.

>> Stephan: Cool, hi, welcome back to another VC Libraries open code review. I'm Stephan T. Lavavej, an STL maintainer, and today we'll be looking at a PR again, PR 2158 extend memcpy, memmove and memcmp optimizations from our contributor Adam Bucior. So let me go ahead and share out my screen. And here we go. 'kay. So resuming the review that I left off last week, I got through up to line, right line 4005 of <xutility>. One of our central internal headers, not the most central, but fairly central. Contains lots of commonly used algorithms, so we'll be resuming there. Adam also pushed one commit to update a comment. So, let's just check that. It adds a comma, addressing the one comment I had from the last time, excellent. OK, so that's good. Uh, let's get this to disappear. OK, so, let's go look at the code. We got all the product code reviewed except for <xutility> and then we've got tests to look at. OK, so let's load this diff. Scroll down to, right line 4005. I seem to recall, at least for this top part I had chosen to split left and right, rather than inline. Let me see if… here's 4005, let me see if the stuff below it would benefit from being split. This part kind of yes, not massively… well yeah here, here this is kind of a… I guess it's a rename plus a refactoring. The diff isn't quite to the point where it's unreadable. This is like, here this is, uh, sort of almost looks like unrelated code getting… uh, it's jumping in and out of add/remove because it sees these empty lines. And the diff algorithm used can be responsible for this sort of behavior. This down here is enough that I think I wanna use side by side, OK. So let's do that, click the gear, split, may as well hide whitespace changes. I could also use the VS Code GitHub extension, but I'm more used to the web UI at this point. The VS Code extension is very nice because it lets you see an arbitrary amount of context around the lines being edited, you don't have to click more. I should get used to using it. OK, so here's where we reviewed <xutility> up to but not including this line. I always pay attention to my inclusive/exclusive issues. So go ahead and resolve this, and let's pick up where we left off. OK, so this is the _Copy_unchecked algorithm. Here we are copying a range [_First, _Last) to a destination iterator. It's internal and it's unchecked, saying that we are going to assume that the iterator range is valid and that we have sufficient space in _Dest. We have outer layers, um, like the publicly accessible std::copy function that will perform iterator debugging checks when possible to do things like make sure that the first and last iterators are not reversed. If you accidentally say, like, (v.end(), v.begin()), or if you mismatch them into different containers, like, uh, (v.begin(), v2.end()), that would be bad. Or if the destination range does not have enough space, uh, we can detect that sometimes if we can, umm, sense how many elements are in the input range by doing like a difference on forward or better iterators. And if the output range is forward or better, and especially if it's a random access, we can see whether we can form, you know _Dest + N or next(_Dest, N) and see if that's valid. And then once we have verified that the iterators are not reversed, and that there's sufficient space in the destination. We can do what we call unwrap the iterators down to either raw pointers for contiguous things or unchecked class types that don't do iterator debugging logic to sort of avoid overhead, especially in debug mode. Uh, where we don't get inlining or any fancy optimizations. So that's what _Copy_unchecked is doing here. We have a note as a reminder that things other than just std::copy will directly call this. We don't usually note this, but the pattern of having unchecked helpers just exist to implement the public functions is strong enough that when there's direct callers to something unchecked, we did start adding some of these comments here, just as a reminder. OK, so this is changing from _Ptr_copy_cat to _Iter_copy_cat. That's the rename because it's being generalized, and _Trivially_copyable changes to _Trivially_assignable because here we are assigning over elements that already exist, this is not the uninitialized special algorithm that will fill raw memory. So this is correct. This is that make the type traits we're using more fine grained. OK, so down here, this looks like a ranges version let me expand some context. We've got the ranges helper _Copy_unchecked, I can tell it's ranges because it's got all this sentinel stuff. Here, _Ptr_copy_cat, renamed _Iter_copy_cat, _Trivially_copyable changed to _Trivially_assignable, same rationale, writing to an _Out that already exists and not changing the sized_sentinel_for thing: this is the ranges idea – Trying to avoid using the word concept to avoid confusion. – the ranges idea that you can have a range and in C++20 ranges the sentinel that denotes the end of the range does not have to be the same type as the iterator, so it's generalizing the classic iterator pattern from C++98's STL, and this allows you to have ranges like, oh, I have a pointer to a null terminated string, and I know when I'm going to hit the end, if you traverse it from front to back. But I don't know exactly where that's going to be until we actually look at every element, so the sentinel can be a special type that says, hey, I've reached the end of the range if the iterator on the left hand side of the comparison is pointing to a null character. So that's an example of a sentinel that does not have the same type as the iterator. Some sentinels can actually tell you the size of a range, that happens for things like forward or better iterators, where they are the same type, where the sentinel is the same type as the iterator. You just do a classic difference. It can also happen in some cases for something I believe like a list, where the list knows its own size, but, uh, arbitrary iterators may not. Uh, I may be incorrect there is that wrong?

>> Casey: That's not exactly this one, right? So sized_sentinel_for means that the iterator and sentinel can tell you the distance between them. list is an example of a range that's a sized range. It knows its own size, but the iterators and sentinels don't know the distance between them.

>> Stephan: Thank you. OK, I thought I was getting that wrong, and, uh…

>> Casey: you were close. That's definitely, you know, list is the important example, but it's the important example of the other property than the one you were looking at.

>> Stephan: Yeah, the sized_range, OK. Awesome, so yeah, and sized_sentinel_for is definitely the one we want here because at this point we're just being given an iterator and a sentinel, not an entire range. OK, so this is good, uh, let's scroll down some more. Um, OK, now we've got copy_n, the version that takes N number of elements. This is the classic std version, uh, there is no unchecked form because we're doing the unchecking in here. Umm, so _Ptr_copy_cat renamed _Iter_copy_cat, _Trivially_copyable to _Trivially_assignable. Yep, it's not the uninitialized form, so all good. We've got a _Copy_backward_unchecked. Yeah, that looks good. this is the internal version taking bidirectional iterators. _Ptr_copy_cat renamed _Iter_copy_cat, _Trivially_copyable to _Trivially_assignable. Yep, that's good. Nothing about this would be different. OK, _Move_unchecked, _Ptr_move_cat, because we're gonna move elements, is now _Iter_move_cat, that's good, _Trivially_copyable to _Trivially_assignable. Yep, the elements already exist. _Move_backward_unchecked, um, this one goes in the opposite order, which helps in certain overlapping cases. Uh, _Ptr_move_cat to _Iter_move_cat, that's correct, _Trivially_copyable to _Trivially_assignable, again, the elements exist, so that's good. OK, so now for something slightly different. This is one of the things that Adam had called out in his extensive PR notes that I really appreciate. The changes to _Is_all_bits_zero, so this is used by the fill optimization that will call memset. If we're gonna fill it with an element, and if that element happens to be 0, uh, we can just call mems… memset, and it doesn't matter how many bytes it is, as long as all of the bits of that element type are zero. I believe this is this was from a previous generalization of our optimization. This is being further extended to handle nullptr_t, because if we're being given an element, say, say we're being asked to fill a range of pointers, like char*s, const char*s, whatever. And the element that we're given to fill happens to be nullptr, the literal constant. That's saying, hey, I want you to null out all these pointers. So this will detect that hey, if the element we're being given is nullptr_t, we can just always return true. And we can do so at compile time. What this code would have done is it would have made a constexpr for, whoa, I'm zooming in a bit, It would have made a constexpr object of type nullptr, and then memcmp'd it at runtime. So we would get the answer yes, it's all bits zero, but we would have had to call memcmp to do so. For nullptr we can just statically detect it. So why not? This improves codegen a little bit more. And this does seem like a common enough case to be worth optimizing, like fill a range of pointers with nullptr, maybe, they were uninitialized before, maybe we need to reset them all. Seems totally reasonable and we can do this thanks to nullptr_t being in the type system. When things're in the type system, that's good, when things like 0 is a null pointer constant are rules that exist outside the type system, that leads to misery, as we saw from years and years of experience with C++98. So, if constexpr (is_same_v<_Ty, nullptr_t>) then just always return true. Otherwise do existing code. This is correct because we are already taking this thing by const _Ty&, so we don't need to worry about CV qualifiers. is_same_v is very very strict. It wants the type to be exactly identical and any differences in constness or volatility will cause this to report false. Here this will ignore constness, it ignores value category because we're already taking it by reference, so this is good. And if somebody gives us a volatile nullptr, well they deserve what they get. We'll go through this code path and I think memcmp handles volatile? I think it does. Maybe it doesn't, but in any event it's not going to be a regression, so that's good. And, I'm trying to think, are there any other types that we could do this for? Brain says no, there's no other types that are like nullptr_t, that we can just say hey, you're always 0, every other type Can store something useful. Umm, OK, next, and I was just thinking, um, that you could have something like a struct who's only data member is a nullptr, but we can't sense that without, like, reflection, and plus that would be very pathological/unusual.

>> Casey: empty types? I wonder if empty types would be something interesting to consider for that optimization.

>> Stephan: That's interesting. It's like how often would you be filling a range of empty types?

>> Casey: I dunno, how often do you fill a range of pointers? [laughs] Ranges of pointers, I'll admit, are a little more common, yes, but

>> Stephan: yeah, empty types, you do see them as things like base classes, you see them as things like tag types. You don't really see ranges of them because they would be stateless. So although I'll admit yes, we could potentially detect is_empty. I think it would occur. Yeah, I think it would occur so infrequently that it wouldn't be worth spending extra metaprogramming here, yeah, but that's that's an interesting question.

>> Casey: [unintelligible] fallback to the compile time case? I mean, sorry, the runtime case?

>> Stephan: Right, uh, yeah and this would say, hey, if it's constexpr and value init, it will get, it would get the correct answer. So at worst we get a little bit extra runtime codegen. OK, so now we've got more metaprogramming logic _Can_compare_with_operator_equal. This is asking… I'm reading ahead of it. Can we form the equality expression, and then some of this pointer address convertible stuff that we had before. OK, so let's look at what's going on here. template on _Ty1, _Ty2 and then class default to void, _INLINE_VAR is our macro that expands to inline in C++17 mode and above. We always want that for our constexpr bools, or constexpr constants in general. _Can_compare_with_operator_equal defaults to false, but if we meet criteria it can be true. So this one here just looks wrapped because of the narrow window here for _Ty1 and _Ty2 this is our void_t SFINAE pattern. We basically say hey, we're gonna write an expression that we want, put it inside decltype to get its type, and then smash that type to void_t, uh, using void_t we're always gonna get void out of this. So, if this thing is well formed it will be selected as the partial specialization for this, uh, because any use of this will use this class equals void default. This will be well formed and void is more specific, so we'll take it. But if this expression is not well formed, then it SFINAEs away and you only have the primary template available. This is the void_t pattern for SFINAE that we conventionally use everywhere in the STL, and it… once you learn the arcane trick behind it, it is nice and terse, and fairly simple to parse. OK, so we form std::declval, an imaginary value of type _Ty1&. So we're gonna compare lvalues, but we're not gonna add any sort of constness, if we can say that's == to a std::declval<_Ty2&>, then, we can compare them with operator==, because we usually compare lvalues… Which makes sense… We would be calling this for elements in a range? Do I like lvalues there? That's interesting. Uh, I'm thinking about, oh, proxies, if iterators, when dereferenced, return proxies. Am I comfortable with lvalue references being added here? I'm not sure, I'm going to think about that for a bit. Only, only very unusual types would be sensitive to the difference, vast majority of types don't care. OK, so then we have a separate variable template. This is _Is_pointer_address_comparable. This asks for a _Ty1 and _Ty2. Can we compare the pointers, _Ty1* and _Ty2* with operator==? Uh, for some this will be true, Like, um, char* equals const char*, that's totally valid. But char* equals int*, that's bogus, there's no such conversions that could make that work, so that would be false. And then, regardless of what this reports, because there's no short circuiting at compile time, uhm, we also asked the questions is _Ty1 pointer address convertible to _Ty2, or vice versa? OK, this is interesting. This is that thing that asks, I think this was above, Let me see if I can find it, pointer_address, yeah this thing, nope, that's the first use, this, oh here it is. OK. Nope, that's more use. Was this in another header? Oh here it is, This says are they the same after ignoring CVs and, is it a base of, is _Dest the base of _Source? Where they're pointer interconvertible, meaning there's no pointer adjustments. So, basically are the bits literally the same, if you convert from pointer to _Source to pointer to _Dest, which is true if you're just adjusting CV qualifiers and it's true if you're doing this base transformation. And we also special case, oh, if any of them were void pointer, uh, void*, then you can certainly convert there. I was briefly thinking about does this report true for something like a void* and a function pointer*, which is… or a function* which is, maybe not? But at least below we guard it with, can we even form the equality? Which is fine. OK, so let's jump to that usage. OK, so this is asking can we form the equality expression between the pointers, and, if we try to convert 1 to 2 or 2 to 1 because we don't know exactly which order they've been given, for example, it could be base* and derived* or derived* and base*. We just need one of those to be pointer address convertible, they don't both need to be. Because the compiler, when it performs the conversion, will select the more de-, the more base one to convert them to. So if either of those are true, then that means we can just compare the pointers using memcmp. OK, I think this all makes sense to me. Um, the fact that _Can_compare_with_operator_equal is always answering the question means that we're not relying on this to return whether they're equality comparable at all, this is merely refining, when this reports true. I also see, there's no real reason to refactor this into terms of conjunction and disjunction. There might be a small throughput improvement. To not have to ask these questions if it's not comparable with operator equal at all. I'm not too worried about that. If we ever find throughput issues we can always refactor this later. Right now it's not really refactorable because there's no struct version of this. These are all, uh, variable templates, so this is, this is good. OK, so this is being used down here, but there's one change happening here. Um, this is in the implementation of _Can_memcmp_elements. Uh, previously we used to ask, are they the same size? And are they integral and non-volatile? And then we have a specialization, that handles if that's false, yes. After all these, yeah. So that's what that was doing. This is being changed. We're now going to permit volatile here. We keep the size of _Elem1 and the size of _Elem2, we keep _Elem1 integral, we keep is_integral_v<_Elem2>. This is clang-format being kind of bad, but that's OK. OK, uh, was it intended to handle volatile here? I need to look at the discussion notes. Uh, let me just open up in tab 2158. OK, this is _Can_memcmp_elements. All these functions are named similarly, OK. Pointers to pointer-interconvertible. OK, this doesn't say anything about memcmp. It says it disabled the memcpy and memmove optimization for volatile, but, this memcmp was already disabling it for volatile. So and now that nonvolatile logic is being removed. Why is this being removed? is_integral, because this is a standard primary cat…, uh, this is a standard type trait for one of the primary type categories, meaning the, sort of the entire universe of types is divided up into 14 or so primary type categories like integral, floating point, nullptr, void, and a few others. All of those ignore top-level CV qualifiers. So is_integral<int>, const int, volatile int, and const volatile int are all true. Here we were excluding volatile and now it's no longer being excluded. Does anything else handle that here? This asks… once we're satisfied that they're the same type and they're both integral, then you can memcmp if one or other is bool, or if their negative one values are the same, then we handle bytes, we handle pointers. Otherwise, we report false, so this would report true for volatile int. I don't understand why volatile is being removed there. Ah, OK. It's being lifted up a level. This is asking _Can_memcmp_elements, and we use it, uh, I guess we have _Can_memcmp_elements_with_pred in the middle here, yeah. And then _Can_memcmp_elements_with_pred is used here and the _Equal_memcmp_is_safe_helper, this asks, hey are _Iter1 and _Iter2 contiguous iterators, and that the iterators don't point to volatile stuff. So this is where volatility is being excluded. OK, so I believe that's correct, but I think a comment needs to be changed, so one of the things I look for when code is significantly changing, is that if there are any comments around, it is quite possible to change the code such that the comments become inaccurate. So double checking the comments for validity is important. Here, the volatile check is being removed, we've got this big comment here, and this was describing the old code. It said _Elem1 and _Elem2 aren't top level const because we remove_const_t in an outer layer. And then we talk about integral types being eligible when they can't be volatile, and this was intended to map to this check here. That's no longer here, so I think at a minimum, this comment needs to be updated. Either we just need to strike this bit about volatility, or probably better, we should just add some parenthetical note like, this being- this is being checked, in – What was the layer? _Equal_memcmp_is_safe_helper, or we could just describe that it's checked before using this. So I will ask that. OK. [under breath] get back to go. backtick. backtick. OK, it looks like the is- We'll just grab the whole thing. etc. checks are being lifted up to the (and get the other thing…) [under breath] Where is it? Here. Iterator is volatile, so it's the _Equal_memcmp_is- – what I want to do is double click but it grabs the space at the end. I guess I'll take it and delete the space. Oh it pastes without the space, interesting, _Equal_memcmp_is_safe_helper layer, which is fine. However, I or– However, the comment. They can't be volatile. [unintellegible] Ope, I don't want a space there. The comment they can't be volatile above was referring to the checks that have been moved Should this comment, or, should we add a parenthetical note to this comment mentioning that volatility? That's the right phrasing. Here we said we remove_const_t before using _Can_memcmp_elements, I can just copy that, volatility has already then handled similar to the comment above. OK, see if that makes sense. It looks like the !is_volatile_v<_Elem1>, etc. checks are being lifted up to the _Equal_memcmp_is_safe_helper layer, which is fine, however the comment they can't be volatile above was referring to the checks that have been moved. Should we add a parenthetical note to this comment mentioning the volatility has already been handled similar to the because we remove_const_t before using _Can_memcmp_elements comment above? OK. Yeah, this is, although this is all like variable template metaprogramming, really it's a question of, like, preconditions and postconditions. Here, there, this thing is assuming certain things about its inputs, that they're not const cause that's already been handled, that they're not volatile, because volatility has already been handled. So we're just really documenting our preconditions, which is important because there's no real way to debug through this stuff when it's variable templates. OK, next up, uh, we had included a performance note in the old code saying, hey, if you're trying to compare like int* to void*, we're just not gonna bother to handle that. That is now being handled by the new _Is_pointer_address_comparable stuff. So that comment's going away, so that's great. So here this is, after the case of we can handle same size integrals, uhm, which handles the usual arithmetic conversions. We have various other special cases like this one which was previously added. We can compare std::bytes even though they're not integral, here if we have pointers to some underlying _Ty1 and _Ty2 elements, We used to say we can compare them only if they're the same, pointing to the same element type. Ignoring CV qualifiers. This says if you're comparing two ranges and the range elements themselves are int* and const int*, then those are different types. But comparing them, we know that comparing each pair of pointers is not going to adjust any bits in the pointers, in the addresses, so we can just call memcmp on the whole thing. This optimization I think, actually goes back to the original implementation we had, circa 2007 or so, when I started working here, and it's been extended since then. So, that retains that behavior, and then additionally extends it to, oh! if you're comparing int* to void*, we know that is not going to do any sort of weird address conversions. And that's now all centralized in _Is_pointer_address_comparable, so that's good, like that. OK. Now this is being refactored. There used to be _Pred_is_consistent_with_memcmp. this is now called _Can_memcmp_elements_with_pred. So let's read the new explanation. _Can_memcmp_elements_with_pred<_Elem1, _Elem2, _Pr>, making sure that it matches the names, reports whether the memcmp optimization is applicable given contiguously stored elements, this avoids having to repeat the metaprogramming that finds the element types. OK. _Elem1 and _Elem2 aren't top level const here. OK, this is talking about how we've already handled the top level constness, and this replaces the old stuff about… thing about just whether the predicate invocation is transparent, uh, and this was always kind of weird, so I'm glad to see that going away. OK, so this is handling equal_to, OK, so, with equal_to<_Elem3>. Yeah, that's the name, we need to make sure that both _Elem1 and _Elem2 are convertible to _Elem3 without changing object representation. We use _Iter_copy_cat for this task. And _Elem3 can be safely memcmp'd with itself. OK, that makes sense because we're, on input, we're converting _Elem1 and _Elem2 each to _Elem3. So that needs to not change object representation, and then within equal_to, that comparison, we need to see, hey, can we use memcmp for that, so template on class _Elem1, _Elem2, _Elem3, _INLINE_VAR constexpr bool _Can_memcmp_elements_with_pred for 1, 2, and if the predicate type happens to be exactly equal_to<_Elem3>, and I was just thinking, ohh, but what if _Elem3 is void, and we've got uh, specialization down here handling that, so here we know _Elem3 is not void. So we're going to answer, or ask three questions. It looks ugly because of clang-format. First, we ask, uh, the _Iter_copy_cat, if we were going to copy from _Elem1* to _Elem3*, we're just forming pointers, even though, we're forming imaginary pointers, these aren't actually being passed to us. If that is _Trivially_constructible, that says without changing object representation, I don't know if I believe this because we also want them to be the same size. I need to go look this up, because something like, say unsigned char to unsigned short. That's not, that's trivial as far as the standard is concerned, but it's going to widen the elements by inserting, you know, extra zeros, so we can't, like, memcmp them in place. OK, so I'm gonna check that. Then I ask the same question for _Elem2* to _Elem3*, _Trivially_constructible, and can we memcmp elements _Elem3 to _Elem3. This ignores top level CV. OK. It's interesting that it's ignoring top level volatility. OK. OK I was gonna check _Trivially_constructible, so that's in the _Iter_copy_cat, we're on line 4564, see if we can find that, _Trivially_constructible. OK, this asks are you _Pointer_address_convertible and are you is_trivially_constructible_v. This is the bit from the core language. Is this the thing that's going to require them to be the same size. I'm a little nervous that we are sort of introducing new concepts – [laughs] there I go, saying concepts – new ideas, that do not map to the standard type traits. When I see _Trivially_constructible, I'm generally assuming that we're referring to like std::is_trivially_constructible_v. It begins to be worrisome when we start introducing extra conventions, especially attached to existing terminology. We've… we've already had issues in the STL, they haven't really caused bugs yet, but we just have to be real careful about it, where we have type traits that are sensitive to things like top level CV qualifiers, where the standard primary type categories are not, and we haven't really done a good rigorous job of documenting exactly which things care about top level CVs, and which don't. Uhm, that's like one layer of issues, that we've successfully handled so far, maybe we'll need to do something about that in the future, but this is like one step beyond CV qualifiers. So let me let me check this _Pointer_address_convertible. I'm pretty sure this is the one that requires the same size. Oh, here we go, here's the _Trivially_constructible that's saying same size and compatible. This is _Trivial_cat, _Trivially_constructible, _Is_pointer_address_convertible. This is when you're just pointers to _Source and _Dest. Oh if the things themselves are pointers, then we know, of course, they're the same size, but if they're not necessarily both pointers here, then that's when we require them to be the same size. Yeah, this, uh, I'm more nervous about this, it does mean that the usage below is fine, uh, which is why I was originally looking at this. We were on 4564 I think. Yeah, we were around here. It is nested. That's the thing that makes it kind of OK, it's nested within _Iter_copy_cat. But now that I'm looking at this, the second time, I'm increasingly uncomfortable with the fact that we just see _Trivially_constructible here, and it expands to something more precise and more restrictive than just trivial constructibility. I'm going to add a comment about this because it's really a comment about naming. It could be addressed by introducing either different names or more clear names. Like one of the… sort of the only thing that makes this whole metaprogramming thing bearable, is that our names are generally pretty precise. When I see something like, you know, _Iterators_are_contiguous. As long as we've you know, carefully verified the definition of this thing, I don't need to worry too much about the actual usage because the type trait, you know, says what it does. But when something says _Trivially_constructible and it's doing something different, then it's an opportunity to get confused, either in cases where we really do want the more general form given to us by the standard and we're using something for convenience that happens to be more restrictive, or vice versa, which I think is more likely. We want this more restrictive form that has tests like same size and compatible, but if we accidentally never go through this centralized machinery, we start getting the wrong answer. And the usage would look like, what if on like 4564 if we accidentally didn't say, like, _Iter_copy_cat::_Trivially_constructible, if we just said, like, is_trivially_constructible_v, that would be super bad. And if the name were anything different, that didn't mirror the standard wording so much, I wouldn't be nervous, because when I see some new name, either a new arrangement of words or ideally different words entirely, then I don't come to it with those assumptions from reading the standard, like when I see, what was it, _Same_size_and_compatible, yeah, this does not map to anything existing in the STL, so if I see this, A. it tells me what it does, but B. I know I need to look up the definition to check, OK, what does it mean "compatible". It's that in fact, that _Trivially_constructible is using the same words, but then is adding extra things. I don't know if I necessarily want you know like _Same_size_and_compatible_trivially_constructible or something, but, this, I think, I'm concerned about it so I'm gonna comment. I think it's these three that I care about now. Here, oh, I don't wanna – I don't wanna get that. I guess it gives me no choice because this is what I would get in-line. I'll just comment on this one line and I'll say that all of them are affected. OK. After reading usage of these. [under breath] what should I call them? Constants? Let's just say, after reading usage far below these definitions. I'm increasingly uncomfortable with, and let's be explicit about exactly which ones, _Trivially_constructible, _Trivially_assignable, and, _Trivially_constructible_and_assignable, using Standard-terminology words, as seen in is_trivially_constructible_v etc, but adding additional conditions, specifically _Same_size_and_compatible. In all of these layers of complicated metaprogramming, clear naming is the only thing preventing massive confusion. I believe we should choose different names for these properties. So we… to avoid any confusion, [under breath] conversion, confusion, confusion between is_trivially_constructible_v and _Trivially_constructible, etc. They don't need to be super duper verbose, for example, Make a example here… _Same_size_and_compatible_and_trivially_constructible is probably too verbose, but introducing a different word somewhere, somehow could really help. No specific ideas yet. Hopefully this makes sense. After reading usage far below these definitions, I'm increasingly uncomfortable with _Trivially_constructible. Let me say – let me say the naming, 'cause the logic is fine. The naming of, using standard terminology words, At the – I'll just note it, I'll just note it at the end. The logic is fine, this is purely a naming concern. OK. After reading usage far below these definitions, I'm increasingly uncomfortable with the naming of _Trivially_constructible, _Trivially_assignable, and _Trivially_constructible_and_assignable using standard terminology words as seen in is_trivially_constructible_v, etc., by adding additional conditions specifically _Same_size_and_compatible, in all these layers of complicated metaprogramming, clear naming is the only thing preventing massive confusion. I believe we should choose different names for these properties to avoid any confusion between is_trivially_constructible_v and _Trivially_constructible, etc. They don't need to be super duper verbose, for example, _Same_size_and_compatible_and_trivially_constructible is probably too verbose, but introducing a different word somewhere, somehow, could really help. No specific ideas yet. The logic is fine, this is purely a naming concern. OK, but we've got the _Same_size_and_compatible condition, which excludes bool shenanigans. So we don't need to worry about unsigned char and unsigned short somehow activating memcmp, which would be bad. OK, so let's resume 4564. OK, so this is good, this is generalized. Ah, OK. Now, If our predicate happens to be equal_to<>, then we know we're just going to directly compare _Elem1, _Elem2 so we can immediately ask _Can_memcmp_elements. This does not remove any CVS. Do we do that above? _Equal_memcmp_is_safe_helper. OK, this calls it with _Iter_value_t, and the iterator value type is not gonna have any CV qualifiers. OK, so, we don't need to worry about that here. In fact, this is sort of… No, no, somebody very strange could say equal_to<const int>, so removing CV on the _Elem3 is good here. OK. OK, so no reason to worry about CV qualifiers there. Next, ranges::equal_to is also transparent, so if we're in concepts mode and our comparator is ranges::equal_to, then just _Can_memcmp_elements. That's good. Ah OK, finally, _Equal_memcmp_is_safe. We've got a helper. It's being refactored a little. It reports whether we can activate the memcmp optimization for arbitrary iterators and predicates. It ignores top-level constness on the iterators and on the elements. So, _INLINE_VAR constexpr bool _Equal_memcmp_is_safe_helper, we first answer are the iterators contiguous. They better be if we're gonna call memcmp. _Iter1 had better not be an iterator to volatile. Same for _Iter2, it should not be iterator to volatile and we need to be able to memcmp elements with pred, _Iter_value_t<_Iter1>, the _Iter_value_t<_Iter2>, and the predicate. OK. OK, onward to lexicographical compare. Here we're placing this logic, and I'm sort of skipping over the old logic cause I'm pretty familiar with it, I should be referring to it a little bit more, but I've reviewed this in the past, so when I've seen missing things here, it just sort of inherently jumps out to me. template<_Elem1, _Elem2> _INLINE_VAR constexpr bool _Lex_compare_memcmp_classify_elements. OK, there was no preamble comment to this. It's probably fine. I think we commented below. Do we? Yeah, we don't. We just go straight into _Lex_compare. On the other hand, that's sort of preexisting. We had comments on some of these definitions, OK, I'm not, I'm not gonna ask for a comment there. Maybe in the future we should add one. template<_Elem1, _Elem2> _INLINE_VAR constexpr bool _Lex_compare_memcmp_classify_elements, is_conjunction_v, all these things need to be true. _Elem1, and because we're going to _Lex_compare, they need to be byte-sized. _Elem1 needs to be a character or a bool, _Elem2 needs to be a character or a bool, _Elem1 needs to be unsigned, _Elem2 needs to be unsigned. OK, and this actually does map to what we had before, except now it permits bool. Is that reasonable? Can you do bool less than unsigned char? Yes you can, because the bool will widen. Actually, we promote it all the way to int, but you can definitely less than that. bool less than bool, that works. In fact we recently saw usage of that with less than equal or greater than equal. And, enums. Those I think would not be reported by _Is_character… It's a good question – _Is_character_or_bool. Let's – let's check that. I should have just been reviewing this in VS Code. Let's see if we can get this… search. OK, so this is elsewhere, in <xutility> 4329. Here we go. This reports true for bool, of course. It reports true for char, signed char, unsigned char, and char8_t. It does not report true for anything else. And here's an example of what I was talking about – it does not strip top level const qualifiers. It will reort true only for exactly bool, char, signed char, unsigned char, or char8_t. Because that's interesting, we do not check enums, ohh, but enums are not less than comparable by default, I think. Yeah, oh, well enum classes are not, I think enums get promoted. I don't… I don't know the enum rules well enough without looking them up. I don't use them that often, it's certainly not a regression. We didn't try to handle enums before. is_unsigned will report things correctly, at least for plain enums, I believe. It asks, what if you had negative one? I know for enums you do need to provide bitmask operators. I think for enum classes you don't get less than, you actually need to provide it. I think this is fine. I'm not gonna worry too much about enums here. In theory we could extend the optimization, but we would need to know that the comparison operator is not overloaded. The nice thing about characters or bools is they're not user defined, so there's no way there can be weird overloaded operators. I think that's probably what's preventing us from doing anything here. When we're copying, we know, hey, you've got an enum, there's no way you could overload a copy assignment operator, but for comparisons I think you could have a user defined operator<. OK, so then if we're bytes, OK, this is, uh, this is a conformance bug. Oh, no, sorry! It's not! [laughs] It's __cpp_lib_byte. The classic gotcha that we have is saying template<> _INLINE_VAR is incorrect if you're in C++14 mode. Because you, it's technically non-conformant to explicitly specialize the variable template, without inline. However, if you are inline, it's totally cool. This is OK, because __cpp_lib_byte implies C++17. What that actually means is this should be plain inline. I should actually check. I think we do have cases where, I think in fact it might be above, where when we know we're __cpp_lib_byte, we just say inline directly. Yeah, here it is. _Can_memcmp, yeah, here's the [unintelligible] _Can_memcmp_elements because it's a C++14 available thing is _INLINE_VAR. When __cpp_lib_byte is defined, we are definitely in 17 or above mode. So we can say plain inline constexpr bool. We should follow the exact same pattern here. Let me just copy this whole thing. Actually I can – I can cite it. Um, four, no, that's right line. Left line 4513 in <xutility> Let's get this. OK, so stl, inc, I should add a little search engine that lets me type something like inc and then a file name and it will take me there. I should really do that. <xutility>. Yeah, we just need to autocomplete this part here. I said 4513. Down, scroll up. There it is. OK, hit Y for permalink. I want to, oh it's click and drag. Nope, no, it's shift click. Trying to remember which UI we're looking at. Excuse me, yeah, OK, this is what I wanna quote. It has to be permalink for the inline snippet to show in the comment. We don't need this anymore. OK, this is nitpick level now, it's not needed for correctness because it will expand to inline, but it does follow the existing convention. We were in the __cpp_lib_byte case for _Lex_compare … something or other. Yeah, here it is. #ifdef __cpp_lib_byte. No, I don't wanna comment on that whole thing, no. OK, maybe just this line? Will you cooperate? OK, here we go. Let me paste the thing, OK. Copy this, OK. As this is guarded by __cpp_lib_byte, we should say plain inline here, see: OK. #ifdef __cpp_lib_byte. As this is guarded by __cpp_lib_byte, we should say plain inline here, see: #ifdef __cpp_lib_byte allow memcmp'ing and so forth, OK. OK, so if we're being asked to compare byte versus byte, we will report true. OK, that's good. That's what we were doing before here, except we had to repeat byte three times. OK. And if we don't recognize the thing we report void for the _Pred, which is how we say, hey, you're not actually comparable. OK, Ohh wow this looks kind of terrible. Just 'cause it's so severely wrapped. OK, so we are specializing. _Lex_compare_memcmp_classify_pred. This is the primary template. So if we don't recognize it, it's void. But if we are specifically _Elem1, _Elem2, and less<_Elem3>, then we might be eligible. So we're gonna ask if comparing _Elem3's could be done with _Lex_compare, because that's the comparison that's actually gonna happen, then we need to make sure that going from _Elem1 to _Elem3, and _Elem2 to _Elem3, doesn't do weird conversions. So this uses the type traits we just asked about the naming, _Iter_copy_cat from an an imaginary _Elem1* to an _Elem3*, if that's trivial, meaning same size and compatible, and it's trivial. Then you're not gonna mess with the bit representation at all, and less'ing them is good. And, we don't need to worry about usual arithmetic conversions because they're both being coerced to _Elem3, so we don't need to worry about like an _Elem1 being wider or something and overpowering _Elem3. _Elem3 is always the destination, and similarly _Elem2 to _Elem3, _Trivially_constructible. OK, then return less<int>. This is, as we saw last time, will be used to compare the output of memcmp, so it always needs to be int. Otherwise just return void. OK, good. less<> is transparent, so you can, or we can, immediately skip any concern about that. We just directly ask. Hey is _Elem1 and _Elem2, are they _Lex_comparable? If so, return less<int>, otherwise void, OK. greater needs to reverse the sense, so same pattern. Gotta be careful for copy-pastoes, we would compare _Elem3 versus _Elem3. Here the fact that the comparison sense is reversed doesn't matter. It's going to be comparable through memcmp either way, the reverseness happens here, and then go from _Elem1 to _Elem3 and from _Elem2 to _Elem3. They both say pointers, so that's good. OK, greater<> is also transparent. So this is good, _Elem1 and _Elem2, greater<int>, void, OK. So for ranges, guarded by #ifdef __cpp_lib_concepts, If we see ranges::less, we know it's transparent, so we can do this short form. I was just thinking, should we just derive from the other specialization? But that would really be the same. It would be one line, one extra line of code and it would instantiate more stuff. Better to just repeat this here. So ranges::less, compare _Elem1, _Elem2, report less<int>. For ranges::greater, report std::greater<int>, that's good. OK, it's now the top level _Lex_compare_memcmp_classify. We're gonna ask for _It1, _It2, and _Pred. I was briefly thinking about, is that the usual naming we have? Usually we say things like _Iter, but _It is fine. So _It1 and _It2 need to be contiguous, and _It1 needs to be not volatile and not an iterator to volatile. Same for _It2, had better not be iterator volatile; then, if that's true, emit typename ::_Pred from _Lex_compare_memcmp_classify_pred, give it the _Iter_value_t, this will not have any CV qualifiers. _Iter_value_t<_It2> and the _Pred. OK. This is sort of preexisting. I am not a fan of shadowing. This is not technically shadowing, but this is using _Pred in two different sentences, so when I see this, my brain momentarily short circuits. This is fine, though. I mean it's prexisting. We did avoid it before by having _Pr, at least in the template. I guess we do use _Pred elsewhere. Where do we, do we use _Pred elsewhere? Or is it _Pr? We could avoid this cheaply by saying _Pr. We say _Pr here. This avoids the duplication by saying class _Pr. Did we say _Pred at the memcmp_classify level? Ohh, it used to be a function. And now it's a … that's a helper here. I'm going to ask for it to be, just class _Pr, 'cause it's a little more consistent with what we did above and it avoids this weird quasi-shadowing. Do we have any other cases of class _Pred that I would need to comment on? That's the only one. OK, let me see. Maybe I'll comment on the whole thing just so the context is clear. Naming nitpick: I recommend templating on class _Pr here, which would be more consistent with, and let's get the use of class _Pr above – this one – with the definition of blah above, and would avoid the quasi-shadowing that appears in this horrible thing. Not really horrible, it's just verbose. Ok, naming nitpick: I recommend templating on class _Pr here, which would be more consistent with the definition of _Lex_compare_memcmp_classify_pred above and would avoid the quasi-shadowing that appears in typename _Lex_compare_memcmp_classify<MEOW, _Pred>::_Pred. OK. So now, we're going directly to lexicographical_compare. Before we had functions, _Lex_compare_unchecked. Here. And now it's all being inlined. OK. So that's where all that complexity is going. That's good, these multiple layers are sort of a holdover, often from our previous tag dispatch era, when we didn't have if constexpr, and we didn't have things like decltype, so we really needed another layer of a function template to deduce the unwrapped types, and to switch between I can optimize versus I can't. Now that we have if constexpr unconditionally, even in C++14 mode, because we can always use future technology when we ask the compiler devs, pretty please. And we have things like decltype, we no longer need separate layers of functions. Sometimes we still want functions for helpers, like with, you know, _Copy_unchecked, but sometimes, inlining it is just easier. And that's the case here. Umm, so now std::lexicographical_compare? Which is a lot of syllables. We're adding top level constness, for our most modern convention on everything, except for the predicate, that could have a non-const function call operator for all we know. We verify the iterators are in the right order. We unwrap them. We're removing the constness on _UFirst1 and _UFirst2, because we're actually going to iterate through them, because we're actually doing the fundamental loop. So that's where that's going. Now we're gonna ask, OK, the _Memcmp_pred, which is the thing we're gonna compare the memcmp answer from. We're gonna _Lex_compare_memcmp_classify the decltype of the unwrapped iterator, same for the decltype of the unwrapped second iterator, and the _Pr. if constexpr so let's see if we're eligible for the optimization. If _Memcmp_pred is not void, then we are eligible. So let's do something cool. But wait! If we're in _HAS_CXXX20 mode, then we are required to be constexpr. This memcmp thing is incompatible at compile time. So we need a runtime test that says if we're in 20 mode then we had better not be std::is_constant_evaluated. Only then at runtime can we do this cool thing. If we turn out to be actually being invoked for compile time, this will turn out to be false and we'll end up doing the raw loop that is constexpr friendly. So this pattern is quite common throughout the STL, and if we're not eligible at all for the optimization, we never even bother asking that, we constant evaluate it, thanks to the wonders of if constexpr. This also explains why this is not an if constexpr else, because we do need this fall through in the case that the runtime test falls through and as a final aside, it is extremely intentional that this is not if constexpr (is_constant_evaluated), the compiler will actually warn at you if you do that, because that forces the answer to always be yes, it is constant evaluated, which is not what you want. This needs to be expressed as a runtime test. OK, so if we end up being eligible at compile time and runtime for the optimization, we get the differences of the iterators, and that's the number of elements we're looking at. We static_cast from ptrdiff_t to size_t. We know that they're in the right order because we verified them so we don't need to worry about reverse things. We call our helper memcmp taking a count. We give it the unwrapped raw pointers or unwrapped iterators and we're gonna compare for the lesser of _Num1 and _Num2 elements, we use std::min, parenthesize to avoid macro expansion, get the answer out, this is very similar to what we had before, and then we compare. If it is less than zero, if it is, less than meaning as judged by the pred, this handles the reverting … the reversing of behavior. Then we'll immediately return that. So if it ends up being less than zero, we'll return that. Otherwise, if it's greater than zero, we definitely want to return false. If it's exactly equal to 0, the only way we can return true is if _Num1 one is less than _Num2, meaning the first sequence is shorter. This handles the prefix case where cat is considered less than catastrophe. If you had a sequence of char. This is exactly equivalent to what we had before. This also, by the way, this correctly handles the case where the comparator is std::greater, that only – if you pass std::greater as the comparison, that only affects the answer when the elements compare non-equal. A lexicographical_compare with std::greater will still say that a shorter sequence is considered lexicographically before the longer sequence. It doesn't reverse that part, because in some sense, lexicographical_compare doesn't know that it's reversing at all. Maybe it's only comparing the sizes of strings or something. It just has a rule. If all the elements are considered equivalent, then shorter sequence is lexicographically before longer sequence. OK, so that's good. Next, here we go, so I guess the conclusion is that what that means is that sorting a sequence of strings by lexicographic std::less and then sorting it … sorry, comparing them with std::greater is not the same as just doing it with std::less and then reversing it, because it's going to handle different length strings differently, if that makes any sense. OK, otherwise, if we are not eligible for the memcmp optimization, like we're dealing with user defined types or if we are in constexpr land, we need to do the raw loop, and so we iterate. We've initialized everything already, so as long as _UFirst1 is not _ULast1 and _UFirst2 is not _ULast2, we have elements of both sequences, we can do the comparison. At the end of the loop, we'll increment _UFirst1, we'll increment _UFirst2. We've got this void cast here to handle overloaded operator comma because being a standard library implementer is fun. We have to defend against all sorts of interesting user behavior. Something to compare. Do it. We're gonna compare *_UFirst1 against *_UFirst2 using the _Pred; We will run it through our _DEBUG_LT_PRED helper. This detects cases where the user predicate is incorrect and returns true when an element is less than itself. That should never ever happen. This detects incorrect use of, like, less_equal. So if it's considered less than we return true, Otherwise we'll reverse it, and if two is less than one, we'll return false. Otherwise, we'll keep going, because they're equivalent. At the end, they are lexicographically less only when the first sequence is shorter than the second; that happens when _UFirst1 has been exhausted, it's equal to _ULast1, and _UFirst2 is not exhausted, it's not equal to _ULast2. So this is translating, in fact, basically moving this code around that was already up here. GitHub doesn't show moves, but, it's just a move. If I was extremely paranoid, I would diff before and after as I do elsewhere. Here, the code is straightforward enough that I can visually see that it's all correct, and it hasn't been mutated in any weird way. OK, so that is for. lexicographical_compare with a pred. Now we have lexicographical_compare without a pred. This one is just gaining const on all the iterators. Nothing else is happening here. I don't actually know why … I guess it's too much of a change for GitHub to highlight const four times in this case, but that's what's happening. And then we just passed less<>, OK? For the parallel version, _ExPo&&. These are all const-ifying. OK, this one's not being parallelized right now, so we just call the std version. OK, that's good. This one is the one that doesn't even take a pred, but it's parallel. Again, we're adding const to all the iterators. OK. Yep. OK, now in the concepts world this is the _Lex_compare_three_way for the <=> operator. OK, so. Template on _Elem1, _Elem2, _Cmp, I'm always scanning for non-ugly names. This is the _Lex_compare_three_way_memcmp_classify_cmp By default, not eligible. We report void, but, if we're given the std::compare_three_way function object then we might be eligible. So using _Comp = conditional_t … We're gonna ask, can we _Lex_compare_memcmp_classify_elements<_Elem1, _Elem2>. This uses the memcmp thing we defined above, because ultimately that's what we wanna do. We wanna ask, hey, are you memcmp-able? But we also need to make sure, are these elements just three way comparable at all? So is it, and this standard, I want to say this is a concept, three_way_comparable_with, const _Elem1& versus const _Elem2&. If that's true we'll return compare_three_way, using the same sort of, this is what we're gonna compare memcmp's result with, otherwise void. OK, we've got some internal concepts, this is all guarded by __cpp_lib_concepts. That's because not all of our front ends support concepts yet, they will soon! Then this will just turn to _HAS_CXX_20. So if we are given _Ty1 and _Ty2, _Can_strong_order requires, given a const _Ty1& _Left, and a const _Ty2& _Right, we can call strong_order(_Left, _Right)? This is, interestingly, a function object in the STL, so we do not qualify it. I think it's not technically a function, so it's not vulnerable to ADL. I think the existing convention is we don't qualify it, but I can't remember if we actually call this. Ooh, that's interesting. So here I did end up – I think I wrote this code – Yeah, this is familiar. I did qualify this, because it looks like a function. Yeah, this is qualified here too. It's technically not. Here, we made sure that strong_ordering was not in scope, and then we're doing ADL call. I would feel better with a _STD here. It is more consistent with existing usage. I can quote this. This is in <compare> line 700. It's a nitpick. That's influenced by how much I hate and fear ADL, the argument dependent lookup that we're constantly on guard against. When I see the qualification, I'm like, ohh, no ADL, this is, you know, fun and happy. And when I don't see the qualification, I'm like, oh, could this be ADL? Could we be hijacked by a better overload? [under breath] Where's <compare>? Here we go. I wanted – nope, I don't want this PR. On line 3…, no, line 700. That's, ope, and I've got the PR up. Sorry about that. Whenever I tap my trackpad, it becomes a click, OK, here we go. Get a permalink by pressing Y. Here's the call to std::strong_order. OK, going inside <utility>, this occurs to all these. So, nitpick: Although this technically isn't a function, and therefore is invulnerable to ADL – I can expand this for any viewers out there who are not versed in the standard acronyms – Argument Dependent – and I don't do this for everything, like SFINAE, but may as well. This is also not universally known – Lookup. We've conventionally qualified it elsewhere, just to avoid any confusion. Occurs below for weak_order and partial_order. Example of … or example precedent? [unintelligible] Nitpick: although this technically isn't a function and therefore is invulnerable to Argument Dependent Lookup, we've conventionally qualified elsewhere just to avoid any confusion. Occurs below for weak_order and partial_order. Example precedent: return _STD strong_order(_Left, _Right). OK. Ohh, and this just occurred to me. This is called _Can_strong_order, that thing in <compare> was called _Can_strong_order. [under breath] thought it was here, _Can_strong_order. That's nested within the fallback. It's nested within this namespace. Technically … it is actually shadowing like there's a std::_Can_strong_order if that's been included above, although here I think <compare> is actually included above, but it's the same name. I'm really uncomfortable whenever I see the same name reused in the STL, even if there's no actual shadowing. I would prefer any other name; that, or lift this up. Like here, the only reason I nested it in was because I didn't think anybody else needed it. But if we actually do need it now … This is trying to call the std function object that we've defined. Lifting this out would be better. One fewer concept and no shadowing. Let me suggest that. OK, so let me … shift-select this, excuse me. OK. Just comment on maybe this thing. There we go. Actually, this I'm gonna say … I'm gonna say duplicates … this appears to … [unintelligible] not 100% sure … this appears to duplicate the helper in <compare>. template … yep, it's concept, _Can_strong_order. It's testing the std function object. Yeah, looks exactly the same. If they are indeed exactly the same, testing whether we can use the Standard function object. Lift it out of – let me copy the namespace. I recommend extracting the helper in <compare> out of namespace _Compare_strong_order_fallback so it can be used here. This would avoid any quasi-shadowing/confusion. OK, how's that look? And I need to say, occurs for the following concepts too. I had nested the helper concepts in their namespaces since I didn't expect any further use of them, but didn't intend to prevent wider use, OK. This appears to duplicate the helper in <compare>: concept _Can_strong_order, if they are indeed exactly the same, testing whether we can use the standard function object, I recommend extracting the helper in <compare> out of namespace _Compare_strong_order_callback so it can be used here. This would avoid any quasi-shadowing/confusion. Occurs for the following concepts too. I had nested the helper concepts in their namespaces since I didn't expect any further use of them, but didn't intend to prevent wider use. OK. _Can_weak_order, _Can_partial_order. OK, getting close to the end of <xutility>. Let me check real quick, we're around line 5000. We are almost at the end? Yeah, we're almost at the end. OK, I'll get to the end of this file and we'll call this a review or a video review. We still have more files to look at. OK, here's the end of the concepts. OK, let's see. Is this all added? No, we're going back to deletions. template on _Elem1, _Elem2, _Lex_compare_three_way_memcmp_classify_comp, given _Elem1, _Elem2, and the strong_order customization point object, This is the type of the std::strong_order function object, using _Comp. So we are, if we're given strong_order, We're going to ask, can we _Lex_compare_memcmp_classify_elements<_Elem1, _Elem2>, and can we strong_order _Elem1, _Elem2 meaning can we call the std::strong_order function object on them. Then let's emit strong_order CPO. Otherwise void, OK. For weak_order, same question, can we use memcmp? Can we weak_order? Here, I'm looking for copy-pastoes, if so emit weak_order CPO. And, finally, for partial_order, still can we memcmp one and two, can we partial_order _Elem1, _Elem2? If so, emit partial_order CPO, OK. Now for class _It1, _It2, and _Comp, the _Lex_compare_three_way_memcmp_classify, given two iterators and a comparator, we need to ask, are _It1 and _It2 contiguous iterators, and _It1 is not an iterator volatile, and _It2 is not an iterator volatile. And, if that's the case, then let's report the _Comp returned by this. I see the same quasi-shadowing that we might be able to avoid with _Cmp, so I'm gonna ask for that. Let's ask, _Lex_compare_three_way_memcmp_classify_cmp, give it the iter_value_t from _It1, iter_value_t from _It2, and then _Comp. OK, here I'm trying to catch cases where we accidentally say like _It1, _It1 twice, which would be catastrophic and missed in a lot of cases. OK, so this is all good, except quasi-shadowing, so I'll ask for that. Let's see. Similar issue as before, can we use class _Cmp to avoid the quasi-shadowing of … or just avoid quasi-shadowing here. class _Cmp, yep, that'd be nice and distinct, OK. And now the top-level function for users, we're adding top-level const to the iterators, all of them. We already were not const-ifying _UFirst1 and _UFirst2, so no change there. All of this is now being lifted up, that's being extracted into those helpers, so we can ask here: the _Memcmp_pred, let's call _Lex_compare_three_way_memcmp_classify the decltype of _UFirst1, and _UFirst2, and the _Cmp. If it's not void, then we're eligible at compile time. We need to see if we're eligible at runtime. Here, the three way is always C++20, so we don't need any if C++20 stuff around here. OK. It's not constant evaluated, then call memcmp. If they end up being the same, then we need to compare the lengths with the memcmp _Pred. Otherwise compare against zero. So this is not handling the greater thing. This would be, this is very different from the plain lexicographical_compare, where we never wanted to use the predicate that we emitted to our metaprogramming machinery on the lengths. Here, the _Pred can't be greater or whatever. It can only be strong_order, weak_order, or partial_order. Do I believe that? It can be user defined. That's interesting, I'm gonna need to double check that. That's extremely interesting. What if it's a user-defined comparator that reverses the sense? I'm going to need to check that. This part is fine. You compare against zero. OK. This one's really interesting. Uh, let me … lexicographical_compare_three_way … we don't have any – we don't have any test coverage for custom <=> comparators. lexicographical_three – ohh compare_three_way. Defined in clause 25. Oh, OK, I think I think we're correct, so this says in sort of mathematical terms, find the smallest integer that you see different elements, so the first elements that don't match. If you find one where it's not zero, you just return it. If they all end up happening to be equal to zero, meaning they're all equivalent, then, ohh, <=>-ize, always <=>. OK, so this is very much like, this is exactly like the stand… the classic one where the classical one says if the comparison resolves before the end, return whatever the comparator said, so std::less, std::greater, user less, user greater, whatever, you return that, but, if they end up all being equivalent elements, then the shorter sequence is considered less than, lexicographically less than, the greater. You don't use the user comparator there. This here says, let E(n) be the user comparator on the n-th elements of the sequences. If the comparison – if there are different elements that we encounter, return the user comparison. If you don't, then you ignore the user comparison. You directly open <=> the lengths of these, so the user comparison could be returning a strong_ordering of, you know, less or greater that's reversed. It could be doing like a std::greater type comparison, but you are not supposed to use it on this case. So this says that we've got a bug. We need test coverage for it as well, OK? And I guess I noticed this because this pattern of using the _Memcmp_pred twice did not occur for the std::lexicographical_compare, the classic one. So even though it does look like it's consistent here that we're converting these two <=>s over to the _Memcmp_pred machinery, that difference in pattern is what clued me in, this is not what we want. OK, so where is the bug? I think the bug is with the _Num1s. Because if memcmp finds a non-zero answer, we found different elements. So. Possibly here. Actually, is this an issue? Are we, this may not be an issue. We only activate this for ones we recognize. We only activate it for our strong_order, weak_order, and partial_order, not for user comparisons because we don't know what they're gonna do, so we can't possibly call memcmp for them. Ah. So at most, at most this is unnecessarily generalized. I think I'm still gonna ask for it to be changed because we can just say <=> here. Yeah it affects the return – oh yeah, ooh it – auto, ohh we would convert the stronger to the weaker, that's possible, right? Yeah? It – I think it does not affect observable behavior. But, for clarity, I would prefer to see a direct use of <=>. I'll put it like that. OK, and it's on the _Num1's because if _Ans is not zero, then we should return whatever this returns. Is this whole thing auto? The whole thing is auto. Ohh sorry it's auto ->, so we've already got the return type here. Yeah I wanna see <=>, OK. I'm going to comment here. OK, ehh, these are horrible, it says paragraph 3 of … I really need a bigger text box. I think big thoughts. Thank you, OK. And we are almost at time, or slightly overtime. WG21-N4892. I Have memorized that number. I'll keep the section number in there for convenience. I'm not gonna bother with all the formatting. Chop this out so it's not distracting. I guess I am a little picky and I'll put that in italics. Gonna put some backticks here. OK. Let's see. Although I don't believe it [under breath] actually, let me summarize this. After some thought, I don't believe this affects correctness, but I believe we should directly <=> compare the lengths here, instead of using the _Memcmp_pred returned by the metaprogramming. This will match the standardese and the classic lexicographical_compare implementation more closely. For the classic impl, this is critical, as the metaprogrammed machinery is capable of reversing the ordering, which we don't want to do for the lengths of equal prefix sequences. For the three way impl, this is cosmetic as we activate the optimization only for strong_order, I'm not going to bother monospacing this, weak_order, partial_order, none of which reverse things like std::greater do. OK. Lot of words. WG21-N4892 alg.three.way/3 Returns … or (e1 - b1) <=> (e2 - b2) if no such integer exists. After some thought, I don't believe this affects correctness, but I believe we should directly. Let me say, but for clarity. After some thought, I don't believe this affects correctness, but for clarity I believe we should directly <=> compare the lengths here instead of using the _Memcmp_pred returned by the metaprogramming, this will match the standardese and the classic lexicographical_compare implementation more closely. For the classic impl, this is critical as the metaprogramming machinery is capable of reversing the ordering which we don't want to do for the lengths of equal prefix sequences. For the three way impl, this is cosmetic as we activate the optimization only for strong_order, weak_order, partial_order, none of which reverse things like std::greater do. OK. And then add some top level const, and we're all good. No ranges stuff here, that I see. OK, that is the end of <xutility>. We can mark that as viewed. OK, so let me alt click and see what test code we have. So we've got all the test code. The only thing I had looked at was test.lst. OK, most of it is new tests, or sorry, it's these decomposed tests. Some new, some decomposed. OK, I will go ahead and submit this review. Thanks – part 2 of the … or, thanks – reviewed this in part 2 of the video review. Looked at the rest of <xutility>, still need to review the test code. OK. Comment. OK so I asked for, comment change about the volatility because I was a little bit confused about that, the renaming that I don't have any good suggestions for, the inline, that's cosmetic. Avoiding the quasi-shadowing with _Pred. Same with _Comp elsewhere. And either std:: qualifying this or just unifying them. And I think it should actually be unified. Uh, the _Comp as I mentioned and then the final thing with the <=>. So all cosmetic stuff/some clarity for naming? But really no correctness concerns, so, this is looking extremely good and I think we're just gonna need to look at the test code. Oh, and it looks like Casey has also reviewed. This can fail in the presence of multiple inheritance, since the pointer to base and the pointer to derived can be equal but have differing bit patterns. Is that true for is_pointer_interconvertible? I thought that's what …

>> Casey: [unintelligible]

>> Stephan: Yeah, this is user … this is library defined. This is why AdamBucior is defining. But he uses is_pointer_interconvertible_base_of.

>> Casey: OK, never mind.

>> Stephan: But that's a good point. We should have a test, ideally. I can add a comment here. I believe that the use of

>> Casey: I guess yeah, thank you.

>> Stephan: Yeah, I can't spell it. I think it's is_pointer_interconvertible …

>> Casey: yeah, is_pointer_interconvertible.

>> Stephan: … base_of. This puppy.

>> Casey: There we go.

>> Stephan: Yeah. handles this scenario, but we should be sure to, we should make sure that there's test coverage for this scenario. I haven't checked yet. Yes, an excellent question, because mishandling this would be very bad. Commented! OK, cool, let's see. Are there any questions for all of the topics we covered? OK, I'm not hearing any. So I think we can call this the end of the video code review. I'll stop sharing my screen. So thanks again for joining us; for next week we may either continue looking at this, or perhaps I'll go off and review the tests, and we'll be looking at another PR next time, so thanks and see you then!